{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgWb11WT-07r"
      },
      "source": [
        "<center><h1>1-cd: Convolutional Neural Networks (ConvNets)</h1></center>\n",
        "\n",
        "<center><h2><a href=\"https://rdfia.github.io/\">Course link</a></h2></center>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac5Js1iML3d_",
        "outputId": "8487a85f-5f3a-429c-b5af-ef0950793f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-21 15:44:12--  https://github.com/rdfia/rdfia.github.io/raw/master/code/2-cd/utils.py\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/2-cd/utils.py [following]\n",
            "--2023-11-21 15:44:12--  https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/2-cd/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2627 (2.6K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   2.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-21 15:44:12 (59.0 MB/s) - ‘utils.py’ saved [2627/2627]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/cdancette/deep-learning-polytech-tp6-7.git\n",
        "! wget https://github.com/rdfia/rdfia.github.io/raw/master/code/2-cd/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QXEas44B52kC"
      },
      "outputs": [],
      "source": [
        "%run 'utils.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8I7lgAEJvPCh",
        "outputId": "a1ac1547-e162-4e82-e7e9-40f329a207fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d7f05c751c7c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_register_onnx_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_custom_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .boxes import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatched_nms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbox_area\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbox_convert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/_register_onnx_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbolic_opset11\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopset11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m from ._internal.exporter import (  # usort:skip. needs to be last to avoid circular import\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mExportOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mExportOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/exporter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagnostics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minfra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m from torch.onnx._internal.fx import (\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mdecomposition_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpatcher\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpatcher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mONNXTorchPatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model_with_external_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/fx/patcher.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# safetensors is not an exporter requirement, but needed for some huggingface models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msafetensors\u001b[0m  \u001b[0;31m# type: ignore[import]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m  \u001b[0;31m# type: ignore[import]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msafetensors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msafetensors_torch\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_full_repo_name\u001b[0m  \u001b[0;31m# for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr_to_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0msubmod_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{package_name}.{attr_to_modules[name]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0msubmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbase_tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m from huggingface_hub.utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTqdmExperimentalWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautonotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnotebook_tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0masyncio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0masyncio_tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/autonotebook.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'IPKernelApp'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"console\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWARN_NOIPYW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIProgress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTqdmWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mIPY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# IPython 4.x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mIPY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# IPython 3.x / 2.x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__protocol_version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__jupyter_widgets_controls_version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__jupyter_widgets_base_version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraitlets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/widgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_button\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mButton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mButtonStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_box\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridBox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_float\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloatText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoundedFloatText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatRangeSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatLogSlider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_int\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoundedIntText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntRangeSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSliderStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_color\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColorPicker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/widgets/widget_float.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidget_serialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoreWidget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_int\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProgressStyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSliderStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/widgets/widget_int.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mIntRangeSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BoundedIntRange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \"\"\"Slider/trackbar that represents a pair of ints bounded by minimum and maximum value.\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/widgets/widget_int.py\u001b[0m in \u001b[0;36mIntRangeSlider\u001b[0;34m()\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0m_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IntRangeSliderModel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Minimum step that the value can take\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     orientation = CaselessStrEnum(values=['horizontal', 'vertical'],\n\u001b[0m\u001b[1;32m    288\u001b[0m         default_value='horizontal', help=\"Vertical or horizontal.\").tag(sync=True)\n\u001b[1;32m    289\u001b[0m     \u001b[0mreadout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Display the current value of the slider next to it.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, default_value, **kwargs)\u001b[0m\n\u001b[1;32m   2684\u001b[0m     \u001b[0;34m\"\"\"An enum of strings where the case should be ignored.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import torch.optim.lr_scheduler\n",
        "\n",
        "from utils import *\n",
        "\n",
        "PRINT_INTERVAL = 200\n",
        "PATH=\"datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xVkUxvwy6a0"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines the structure of the neural network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # We first define the convolution and pooling layers as a features extractor\n",
        "        self.features = nn.Sequential(\n",
        "            #conv1, relu, maxpool\n",
        "            nn.Conv2d(3, 32, (5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv2, relu, maxpool\n",
        "            nn.Conv2d(32, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv3, relu, maxpool\n",
        "            nn.Conv2d(64, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0, ceil_mode = True),\n",
        "        )\n",
        "        # We then define fully connected layers as a classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            #fc4, relu, fc5\n",
        "            nn.Linear(1024, 1000), #4*4*64\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #dropout layer\n",
        "\n",
        "\n",
        "            nn.Linear(1000, 10)\n",
        "            # Reminder: The softmax is included in the loss, do not put it here\n",
        "        )\n",
        "\n",
        "    # Method called when we apply the network to an input batch\n",
        "    def forward(self, input):\n",
        "        bsize = input.size(0) # batch size\n",
        "        output = self.features(input) # output of the conv layers\n",
        "        output = output.view(bsize, -1) # we flatten the 2D feature maps into one 1D vector for each input\n",
        "        output = self.classifier(output) # we compute the output of the fc layers\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "\n",
        "def epoch(data, model, criterion, optimizer=None, cuda=False):\n",
        "    \"\"\"\n",
        "    Make a pass (called epoch in English) on the data `data` with the\n",
        "     model `model`. Evaluates `criterion` as loss.\n",
        "     If `optimizer` is given, perform a training epoch using\n",
        "     the given optimizer, otherwise, perform an evaluation epoch (no backward)\n",
        "     of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # indicates whether the model is in eval or train mode (some layers behave differently in train and eval)\n",
        "    model.eval() if optimizer is None else model.train()\n",
        "\n",
        "    # objects to store metric averages\n",
        "    avg_loss = AverageMeter()\n",
        "    avg_top1_acc = AverageMeter()\n",
        "    avg_top5_acc = AverageMeter()\n",
        "    avg_batch_time = AverageMeter()\n",
        "    global loss_plot\n",
        "\n",
        "    # we iterate on the batches\n",
        "    tic = time.time()\n",
        "    for i, (input, target) in enumerate(data):\n",
        "\n",
        "        if cuda: # only with GPU, and not with CPU\n",
        "            input = input.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        # forward\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # backward if we are training\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # compute metrics\n",
        "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
        "        batch_time = time.time() - tic\n",
        "        tic = time.time()\n",
        "\n",
        "        # update\n",
        "        avg_loss.update(loss.item())\n",
        "        avg_top1_acc.update(prec1.item())\n",
        "        avg_top5_acc.update(prec5.item())\n",
        "        avg_batch_time.update(batch_time)\n",
        "        if optimizer:\n",
        "            loss_plot.update(avg_loss.val)\n",
        "        # print info\n",
        "        \"\"\"\n",
        "        if i % PRINT_INTERVAL == 0:\n",
        "            print('[{0:s} Batch {1:03d}/{2:03d}]\\t'\n",
        "                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:5.1f} ({top1.avg:5.1f})\\t'\n",
        "                  'Prec@5 {top5.val:5.1f} ({top5.avg:5.1f})'.format(\n",
        "                   \"EVAL\" if optimizer is None else \"TRAIN\", i, len(data), batch_time=avg_batch_time, loss=avg_loss,\n",
        "                   top1=avg_top1_acc, top5=avg_top5_acc))\n",
        "            if optimizer:\n",
        "                loss_plot.plot()\"\"\"\n",
        "\n",
        "    # Print summary\n",
        "    print('\\n===============> Total time {batch_time:d}s\\t'\n",
        "          'Avg loss {loss.avg:.4f}\\t'\n",
        "          'Avg Prec@1 {top1.avg:5.2f} %\\t'\n",
        "          'Avg Prec@5 {top5.avg:5.2f} %\\n'.format(\n",
        "           batch_time=int(avg_batch_time.sum), loss=avg_loss,\n",
        "           top1=avg_top1_acc, top5=avg_top5_acc))\n",
        "\n",
        "    return avg_top1_acc, avg_top5_acc, avg_loss\n",
        "\n",
        "\n",
        "def main(batch_size=128, lr=0.1, epochs=5, optim = 'SGD', scheduler = \"\", cuda=False):\n",
        "    model = ConvNet()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if(optim == 'Adagrad'):\n",
        "      optimizer = torch.optim.Adagrad(model.parameters(), lr)\n",
        "    if(optim == 'RMSprop'):\n",
        "      optimizer = torch.optim.RMSprop(model.parameters(), lr)\n",
        "    if(optim == 'Adam'):\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "    else :\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr)\n",
        "    # Create the scheduler\n",
        "\n",
        "    if(scheduler == \"ExponentialLR\"):\n",
        "      lr_sched = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    if(scheduler == \"CosineAWR\"):\n",
        "      lr_sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 1)\n",
        "    if(scheduler == \"ReduceLROnPlateau\"):\n",
        "      lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "    if(scheduler == \"CosineALR\"):\n",
        "      lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10)\n",
        "    if(scheduler == \"Cyclic\"):\n",
        "      lr_sched = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.1, max_lr = 0.2)\n",
        "\n",
        "    if cuda: # only with GPU, and not with CPU\n",
        "        cudnn.benchmark = True\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    # Get the data\n",
        "    train, test = get_dataset(batch_size, cuda)\n",
        "\n",
        "    # init plots\n",
        "    plot = AccLossPlot()\n",
        "    global loss_plot\n",
        "    loss_plot = TrainLossPlot()\n",
        "\n",
        "    # We iterate on the epochs\n",
        "    for i in range(epochs):\n",
        "        print(\"=================\\n=== EPOCH \"+str(i+1)+\" =====\\n=================\\n\")\n",
        "        # Train phase\n",
        "        top1_acc, avg_top5_acc, loss = epoch(train, model, criterion, optimizer, cuda)\n",
        "        # Test phase\n",
        "        top1_acc_test, top5_acc_test, loss_test = epoch(test, model, criterion, cuda=cuda)\n",
        "        # plot\n",
        "        plot.update(loss.avg, loss_test.avg, top1_acc.avg, top1_acc_test.avg)\n",
        "\n",
        "        #Modify the learning rate after each epoch\n",
        "        if(len(scheduler)>0):\n",
        "          lr_sched.step()\n",
        "          print(f\"LR : {lr_sched.get_last_lr()}\")\n",
        "\n",
        "        \"\"\"\n",
        "        # TEST DE CONVERGENCE\n",
        "        if(np.abs(loss_1-loss.avg) <1e-2):\n",
        "          print(f\"Convergence, loss{loss.avg}\")\n",
        "          break\n",
        "        else:\n",
        "          loss_1 = loss.avg\n",
        "        \"\"\"\n",
        "    return loss, loss_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXoiJsO0PI5C"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9bajULaxNrn"
      },
      "source": [
        "# Part 3 -- Results improvements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EXoiIdcxU1E"
      },
      "source": [
        "### 3.1 - Standardization of examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYHwqpujbLWd"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CrXvxIixpec"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4ZTW5Na6uyh"
      },
      "outputs": [],
      "source": [
        "class PCAWhitening:\n",
        "    def __init__(self, epsilon=1e-5):\n",
        "        self.epsilon = epsilon\n",
        "        self.mean = None\n",
        "        self.whitening_matrix = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.mean = torch.mean(X, dim=1).unsqueeze(1)\n",
        "        X_centered = X - self.mean\n",
        "        covariance_matrix = torch.mm(X_centered, X_centered.t()) / X_centered.size(1)\n",
        "        eigenvalues, eigenvectors = torch.linalg.eigh(covariance_matrix, UPLO='U')\n",
        "        self.whitening_matrix = torch.mm(torch.diag(1.0 / torch.sqrt(eigenvalues + self.epsilon)), eigenvectors.t())\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_centered = X - self.mean\n",
        "        return torch.mm(self.whitening_matrix, X_centered)\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = img.view(3, -1)\n",
        "        if self.whitening_matrix is None:\n",
        "            self.fit(img)\n",
        "        img_whitened = self.transform(img).view(3, 32, 32)\n",
        "        return img_whitened"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z3kHNpK6v4t"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    pca_whitening = PCAWhitening()\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: x * 255.0),  # Scale back to 0-255 range, as PCA operates on this range\n",
        "            pca_whitening,\n",
        "            # transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: x * 255.0),  # Scale back to 0-255 range, as PCA operates on this range\n",
        "            pca_whitening,\n",
        "            # transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBxfvxz-6_Dw"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIWjPHTTrc4Z"
      },
      "outputs": [],
      "source": [
        "main(128, 0.001, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3bqZXPXjHYX"
      },
      "source": [
        "### Min-Max scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrztBt57jGjC"
      },
      "outputs": [],
      "source": [
        "class MinMaxScaling:\n",
        "    def __init__(self):\n",
        "        self.min = None\n",
        "        self.max = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.min = torch.min(X, dim=1, keepdim=True)[0]\n",
        "        self.max = torch.max(X, dim=1, keepdim=True)[0]\n",
        "\n",
        "    def transform(self, X):\n",
        "        return (X - self.min) / (self.max - self.min + 1e-5)  # Adding a small constant to avoid division by zero\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = img.view(3, -1)\n",
        "        if self.min is None or self.max is None:\n",
        "            self.fit(img)\n",
        "        img_scaled = self.transform(img).view(3, 32, 32)\n",
        "        return img_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axPcfMbUjMPO"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    min_max_scaling = MinMaxScaling()\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            min_max_scaling,\n",
        "            # transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            min_max_scaling,\n",
        "            # transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrRWlEigjaVX"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcdLeiZsxxgS"
      },
      "source": [
        "##3.2 - Increase the number of training examples by data increase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XWqzmzrXX2L"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuM7dm1qxqpr"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomCrop(28),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            #transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqFUyAm428GP"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrlaa0Hl3pKq"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.RandomCrop(28),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            #transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-0mxOSU3txC"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAIMOW2n31oX"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.RandomCrop(28),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            #transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu0UBrzX4A0g"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igVLludh4M84"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomCrop(28),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            #transforms.RandomRotation(90),\n",
        "\n",
        "            transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MBfDA274RA5"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx_DxTHq4ZxR"
      },
      "outputs": [],
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.RandomCrop(28),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tlbo0je4nFK"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomCrop(28),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "-pvI6nefbbu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(128, 0.1, epochs=50, cuda=True)"
      ],
      "metadata": {
        "id": "8eUMH1sKbh8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7UtNV2QykpZ"
      },
      "source": [
        "## 3.3 - Variants on the optimization algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomCrop(28),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            #transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "ZC51Tal8cEoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCSIQlqYykwO"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True, scheduler = \"ExponentialLR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning stability"
      ],
      "metadata": {
        "id": "pVUGj2BkEzP2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB43VUmVmA5u"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "\n",
        "losses = []\n",
        "losses_test = []\n",
        "\n",
        "for i in range(10):\n",
        "    print(\"Step\", i)\n",
        "    loss, loss_test = main(128, 0.1, epochs=10, cuda=True)\n",
        "    losses.append(loss.avg)\n",
        "    losses_test.append(loss_test.avg)\n",
        "\n",
        "print(\"Mean training loss :\", sum(losses) / len(losses))\n",
        "print(\"Mean test loss :\", sum(losses_test) / len(losses_test))\n",
        "print(\"Standard deviation training loss :\", statistics.stdev(losses))\n",
        "print(\"Standard deviation test loss :\", statistics.stdev(losses_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "mu = 0.7306593440756013\n",
        "sigma = 0.05003281626991144\n",
        "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "plt.plot(x, stats.norm.pdf(x, mu, sigma), label='μ:0.73, σ: 0.05')\n",
        "plt.plot(x, stats.norm.pdf(x, mu, 1), label='μ:0.73, σ: 1')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "w7jvX_IZDv9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZx9b_jEgWno"
      },
      "outputs": [],
      "source": [
        "main(128, 0.0005, epochs=50, optim='Adam', cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie2Yd_b9brc6"
      },
      "outputs": [],
      "source": [
        "main(128, 0.0005, epochs=50, optim='Adam', scheduler = 'ExponentialLR', cuda=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-rgkN_KjX8O"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, scheduler = 'CosineALR', cuda=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UaeW6fX3BZ5"
      },
      "source": [
        "## 3.4 - Regularization of the network by dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6kJXp2uy6Hf"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines the structure of the neural network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # We first define the convolution and pooling layers as a features extractor\n",
        "        self.features = nn.Sequential(\n",
        "            #conv1, relu, maxpool\n",
        "            nn.Conv2d(3, 32, (5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv2, relu, maxpool\n",
        "            nn.Conv2d(32, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv3, relu, maxpool\n",
        "            nn.Conv2d(64, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0, ceil_mode = True),\n",
        "        )\n",
        "        # We then define fully connected layers as a classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            #fc4, relu, fc5\n",
        "            nn.Linear(1024, 1000), #4*4*64\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.9),\n",
        "            nn.Linear(1000, 10)\n",
        "            # Reminder: The softmax is included in the loss, do not put it here\n",
        "        )\n",
        "\n",
        "    # Method called when we apply the network to an input batch\n",
        "    def forward(self, input):\n",
        "        bsize = input.size(0) # batch size\n",
        "        output = self.features(input) # output of the conv layers\n",
        "        output = output.view(bsize, -1) # we flatten the 2D feature maps into one 1D vector for each input\n",
        "        output = self.classifier(output) # we compute the output of the fc layers\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru1mtWLn3htM"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True, scheduler = 'ExponentialLR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UtfKBqr3hSC"
      },
      "source": [
        "## 3.5 Use of a batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhK3_fKw3mpC"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines the structure of the neural network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # We first define the convolution and pooling layers as a features extractor\n",
        "        self.features = nn.Sequential(\n",
        "            #conv1, relu, maxpool\n",
        "            nn.Conv2d(3, 32, (5, 5), stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv2, relu, maxpool\n",
        "            nn.Conv2d(32, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv3, relu, maxpool\n",
        "            nn.Conv2d(64, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0, ceil_mode = True),\n",
        "        )\n",
        "        # We then define fully connected layers as a classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            #fc4, relu, fc5\n",
        "            nn.Linear(1024, 1000), #4*4*64\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.9),\n",
        "            nn.Linear(1000, 10)\n",
        "            # Reminder: The softmax is included in the loss, do not put it here\n",
        "        )\n",
        "\n",
        "    # Method called when we apply the network to an input batch\n",
        "    def forward(self, input):\n",
        "        bsize = input.size(0) # batch size\n",
        "        output = self.features(input) # output of the conv layers\n",
        "        output = output.view(bsize, -1) # we flatten the 2D feature maps into one 1D vector for each input\n",
        "        output = self.classifier(output) # we compute the output of the fc layers\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96FPm1_YgW1p"
      },
      "outputs": [],
      "source": [
        "main(128, 0.1, epochs=50, cuda=True, scheduler = \"ExponentialLR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With all our trials and tests, we will now determine an \"optimal\" model based on experimentations we made before."
      ],
      "metadata": {
        "id": "RlND8quoRPdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines the structure of the neural network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # We first define the convolution and pooling layers as a features extractor\n",
        "        self.features = nn.Sequential(\n",
        "            #conv1, relu, maxpool\n",
        "            nn.Conv2d(3, 32, (5, 5), stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv2, relu, maxpool\n",
        "            nn.Conv2d(32, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0),\n",
        "            #conv3, relu, maxpool\n",
        "            nn.Conv2d(64, 64, (5, 5), stride=1, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2), stride=2, padding=0, ceil_mode = True),\n",
        "        )\n",
        "        # We then define fully connected layers as a classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            #fc4, relu, fc5\n",
        "            nn.Linear(1024, 1000), #4*4*64\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.9),\n",
        "            nn.Linear(1000, 10)\n",
        "            # Reminder: The softmax is included in the loss, do not put it here\n",
        "        )\n",
        "\n",
        "    # Method called when we apply the network to an input batch\n",
        "    def forward(self, input):\n",
        "        bsize = input.size(0) # batch size\n",
        "        output = self.features(input) # output of the conv layers\n",
        "        output = output.view(bsize, -1) # we flatten the 2D feature maps into one 1D vector for each input\n",
        "        output = self.classifier(output) # we compute the output of the fc layers\n",
        "        return output"
      ],
      "metadata": {
        "id": "Oaj4k99PRRCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size, cuda=False):\n",
        "    \"\"\"\n",
        "    This function loads the dataset and performs transformations on each\n",
        "    image (listed in `transform = ...`).\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.CIFAR10(PATH, train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomCrop(28),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "\n",
        "            transforms.RandomRotation(90),\n",
        "\n",
        "            #transforms.GaussianBlur(kernel_size = (5, 9)),\n",
        "\n",
        "            #transforms.ElasticTransform(alpha=250.0),\n",
        "\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201)),\n",
        "\n",
        "            # AddGaussianNoise(0,1)\n",
        "        ]))\n",
        "    val_dataset = datasets.CIFAR10(PATH, train=False, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.CenterCrop(28),\n",
        "            transforms.Normalize((0.491, 0.482, 0.447), (0.202, 0.199, 0.201))\n",
        "        ]))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "zY4L1i8WRVJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(128, 0.5, epochs=100, cuda=True, scheduler = \"CosineALR\")"
      ],
      "metadata": {
        "id": "D6tE2sdMRcKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}